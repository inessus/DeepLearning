# 第六章　深度前馈网络（Deep Feedforward Networks）
  深度前馈网络，又称前馈神经网络，多层感知机，是典型的深度学习模型。前馈网络的目标是函数逼近。例如对于分类器，$y=f^*(x)%$,映射输入$ｘ$到分类$ｙ$,前馈网络定义个映射$y=f(x:\theta)$,学习参数$\theta$,获得最好的函数逼近。

  这个模型之所以称为前馈，因为通过对参数ｘ进行求值，信息流通过中间计算，最后输出ｙ。该模型没有反馈连接，也没有自反馈。如果前馈神经网络包含反馈连接，我们称为循环神经网络（recurrent,neural networks）(参见第十章)

  对于想实践机器学习的人来说，前馈网络非常重要。也是目前很多重要商业应用的基础。例如：卷积网络（一种特殊的前馈网络）用于照片中对象识别，以前馈网络为垫脚石的循环神经网络在自然语言处理上非常有效。

  前馈神经网络之所以称为网络因为由许多不同的函数复合在一起表达。模型一般关联一个有向循环图（directed acyclic graph）来描述函数如何复合在一起。例如有三个函数$f^{(1)}$，$f^{(2)}$,$f^{(3)}$连称一个链。形式为$f(x) = $f^{(3)}(f^{(2)}(f^{(1)}))$,链式结构是神经网络的最普通结构。一般来说$f^{(1)}$称为第一层网络，$f^{(2)}$称为第二层网络,以此类推。链的长度称为模型的深度。这也是深度学习名字由来。前馈网络的最后一层称为输出层。在神经网络训练过程中，我们尽量$f(x)$匹配$f^*(x)$
